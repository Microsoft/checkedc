% !Tex root = checkedc.tex

\chapter{Related work}
\label{chapter:lessons}

The C family of programming language is widely used.  The lack of
bounds checking in C and related languages such as C++ has had
serious practical consequences for computer security and software 
reliability.   There has been extensive work in industry and the
research community addressing the lack of bounds checking in C.
In this section, we discuss related work,  
highlighting key lines of work and describing how Checked C relates to them. 

We begin by discussing the most closely related work to Checked C:
type-safe dialects of C.  These address the underlying problem of
a lack of bounds checking as well as other aspects of type safety.
These dialects are not used in practice, so we look closely at why
this is true for lessons for the Checked C effort.

We then discuss security mitigations that address
security problems that arise from a lack of bounds checking.
These mitigations are widely used in practice.   Checked C
complements these mitigations by providing protection against data
modification and data disclosure attacks.

\section{Runtime-only bounds checking}

The C specification leaves the semantics of out-of-bounds pointer
arithmetic undefined, except for the case of a pointer to one element
past the last element of an array.  It also leaves the semantics of out-of-bounds
pointer access undefined.  This makes it possible to implement
runtime-only bounds checking that is consistent with the semantics of
C and that dooes not require source code changes.  Many such systems have been implemented.  

There are two general approaches used 
for runtime-only bounds checking.
The first approach is to change the representation of pointers to carry
bounds with them.  The second approach uses a side-data structure to
hold bounds information.   There are several different kinds of side-data
structures used.  One kind tracks blocks of memory that are valid to
use.  The block are typically powers of 2 and can range from bytes 
up to 32-byte.  This is used to track ``red zones'' around objects that
are invalid to access.  These are useful for detecting buffer overruns caused
by loops, but may not detect other out-of-bounds access.  Another kind tracks the
start and end locations of objects and can be used to provide object-level bounds checking.   A third approach uses a shadow memory to track bounds information for individual pointers, splitting the bounds information from the pointer.

These approaches work well for testing purposes, but they have issues that
prevent them from being used for production systems.  There are issues
with performance, backwards-compatibility, and constraints on memory
management and layout.  Most fundamentally, all of these approaches add
runtime data to programs, which in turn increases memory accesses, processing 
times, and memory footprint.  They have to pay for generality regardless of
whether it is needed or not. In contrast, Checked C allows re-use of existing data.
It incurs no data overhead for constant-sized arrays or pointers on which no pointer arithmetic is done.   Approaches that change
pointer representations have difficulty interoperating with existing
systems because that changes the layout of data that must be passed
across boundaries.  Approaches that track data on the side generally
requiring hooking memory allocators.  Furthermore, a number of them
constrain memory layout and object sizes to speed up the lookup of
the side data.

These approaches also take control of checking away from the programmer.
Runtime-only checking {\em always} checks, unless the check can be proven 
redundant by compiler optimization.   With Checked C, programmers have
a range of options   The default behavior is to always check. For performance-critical
code, programmers can rely on static checking that proves the checks
are unnecessary or omit checks entirely.

We first describe approaches that change the representation of pointers.
The bcc source-to-source translator \cite{Kendall1983} and the rtcc
compiler \cite{Steffen1992} were used to find bounds errors and
other errors during debugging.  Each changed the representations of pointers to be 
3 words: the pointer itself and an upper and lower bound.   
Steffen \cite{Steffen1992} reports that the rtcc compiler generated code
that was 3 times larger and ran about 10 times slower than the original code, 
likely reflecting the simple nature of  the optimizer for the PCC compiler.  Data
layout compatability is an issue.  Bounds information has to be removed at calls to
standard library  functions and added at returns from standard library functions.
Austin {\it et al.} \cite{Austin1994} describe a pointer representation that
adds a capability in addition to bounds information.  The capability is used to
prevent accesses to de-allocated memory.  The runtime system tracks capabilities that
are valid (memory that has not been deallocated).  

Fail-Safe C is a memory-safe compiler for ANSI C cite{Oiwa2009}.  It
supports all operations in ANSI C,including cast operations.
It represents pointers as pairs, where each pair consist of the base address
of an object and an integer offset from the base address. 
It changes the representation of integers to be pairs as well so that pointers can 
be cast to integers and back.  It also changes the representation of memory blocks in
C to dynamically track their types.  This
supports the C notion that memory locations are dynamically typed; the type
of the value in a memory location depends on the type of the last value stored there.
It use conservative garbage collection to ensure the safety of memory
deallocations.   With the data layout changes, programmers no longer 
directly control memory representations.  This makes Fail-Safe C unsuitable for low-level  systems programming.
It is suitable for applications programs, provided the wrappers for system
calls are provided.  Bytemark benchmarks are 2 to 4 times slower.  OpenSSL RSA
speed tests are 2 to 4 times slower, while AES speed tests are 5 times slower.

We next describe approaches that use side-data structures.    We first
describe approaches that track what memory is valid to access.
Purify \cite{Hastings1992, Unicom2016} detects some bounds checking problems
as well as uses of uninitialized memory and memory leaks.  It is meant for
use during development and debugging.  Purify uses a table that keeps track
of the state of each byte in memory, using 2-bits to represent the state of
memory.  It inserts a small ``red zone'' before and after each dynamically
allocated object and between statically-allocated objects.   It also
inserts red zones between stack frames.  All memory accesses are instrumented 
to  check or update the state for a byte. 
The instrumentation is inserted by rewriting binary code before linking.
Purify detects out-of-bounds memory reads and writes involving red-zone
memory.   It does not detect out-of-bounds
reads or writes that occur entirely within valid memory for other objects
or stack frames. It cannot detect out-of-bounds memory accesses at
the sub-object level.
Hastings {\it et al.} report a slowdown of more than 2 times due to
the instrumentation.  However, this includes additional checking for memory leaks 
and the use of uninitialized memory.

There are a number of other similar commercial or open-source tools available
that detect out-of-bounds memory accesses.
Tools based on binary rewriting include Bounds Checker \cite{BoundsChecker2016}, 
Dr. Memory \cite{Bruening2011,DrMemory2016}, Intel Inspector \cite{Intel2016},
Oracle Solaris Studio Code Analyzer \cite{CodeAnalyzer2016},
and Valgrind Memcheck  \cite{Nethercote2007, Valgrind2016}.  Insure++ 
\cite{Insure2016}
inserts instrumentation using source-to-source rewriting.  It also provides
a mode that does not require recompilation, although details of how that
works are not described.

AddressSanitizer \cite{Serebryany2012} is a tool similar to Purify that is
incorporated into the LLVM and GCC compilers.  It uses a table
stored in shadow memory that tracks that state of 8-byte chunks of memory, using
1/8 of the virtual address space.  It also relies on inserting ``red zones''.
Because it has been implemented in a compiler, it is able to place red zones
around stack-allocated objects.   It cannot detect out-of-bounds memory
accesses at the sub-object level and cannot reliably track out-of-bounds accesses
for objects smaller than 8 bytes.  For SPEC CPU2006, average program execution time
increases by 73\% when checking reads and writes and 26\%
when only checking writes. For SPEC CPU2006, average memory usage is 
3.37 times larger.

Light-weight Bounds Checking \cite{Hasabnis2012} is an optimized implementation of bound
checking that uses ``red zones''.
it focuses solely on bounds checking.  It uses a bitmap to track
which bytes in memory correspond to allocated objects and which do not.
It uses a two-level table to avoid allocating a table equal to 1/8 of the
address space.  It optimizes memory reads by filling red zones with special
values.  If a memory read returns a special value, then a check is done to
ensure that the address was not a red zone address.  It is implemented in a compiler and can guard stack objects.  For SPECINT 2000, average 
program execution time increases by 23\%. For SPECINT 2000, its memory 
overhead ranges between 0.2\% and 44\% with an average of 8.5\%.

Next, we describe approaches that use side-data structures to track
object bounds.   
Jones and Kelly \cite{Jones1997} use a splay tree to track the bounds for
objects in a side data structure.  They insert 
checks for pointer arithmetic to make sure that pointers stay within valid bounds for
objects.  If a pointer goes out of bounds, it is converted to a value that cannot
be dereferenced and that is not allowed to go back in bounds. 
They change checked code to call modified versions of \keyword{malloc}
and \keyword{free}  as well as system-level allocator.  The compiler modifies
code generation for stack allocate objects to call funtions that update the 
bounds information. In a production system, all custom allocators would have to be
modified to update the object bounds information.  

Jones and Kelly implememented their approach in GCC.   The approach easily allows
interoperation between checked and unchecked code.  Objects that are not allocated by
checked code are not tracked.  Untracked and tracked objects are treated as distinct memory regions.  Operations in checked code on untracked objects are not allowed to produce pointers to checked objects, providing some protection to untracked objects.  

Their implementation increases program running
times by a factor of 7.7 to 12 \cite{Nagarakatte2009} for  a set of
23 benchmarks that includes programs from SPEC and the Olden benchmark.
There are other drawbacks to this approach.
Because bounds are tracked at the granularity of objects, it
cannot track bounds for arrays nested within structures.  It also cannot
track bounds for objects produced by custom allocators.  There are also
issues with handling pointers to one element past the last element of
an array.  The approach inserts padding between objects to have a gap.  In some
cases, such as parameters passed on the stack, this is not possible.

The C Range Error Detector (CRED) \cite{Ruwase2004} extends the Jones and Kelly
approach to tolerate out-of-bounds pointers.  They observe that 12 out of
20 open source programs totalling 1.2 million lines of C code break when
out-of-bounds pointers are not allowed.   This observation supports the
design decision in Checked C to allow out-of-bounds pointers and only
check bounds at memory dereferences.

CRED uses a proxy object that
tracks the original pointer value and the object with which it is associated
os that the pointer can go in back bounds.  When a pointer goes out of
bounds, it is replaced with the proxy object address.  This requires
additional checks on comparisons and pointer arithmetic computations.
They find similar increase in program running times.  They suggest
limiting bounds checking to only character pointers. With this restriction,
the increase in execution time  ranges from 1\% to 130\% on a set of real-world
programs.  They do not report on changes in memory usage.

Dhurjati and Adve \cite{Dhurjati2006} describe an optimized implementation of
CRED.  It relies on a whole-program analysis to partition
objects into separate pools.  The pool information is used to partition
the splay tree and  to avoid having to create entries for single-element arrays 
or scalar objects in the splay tree.

Baggy Bounds Checking \cite{Akritidis2008} provides a faster implementation
of the side data structure in Jones and Kelly.  The implementation 
calculates the bounds for any pointer in constant-time.   To acheive this,
the implementation constrains object sizes to be powers of 2.  It also reserves 
1/var{n} of the virtual address space for a table, where \var{n} is the smallest 
allowed object size (16 in the implementation).  The table stores the size of the
enclosing object (if any) for each \var{n}-byte chunk of memory.   Baggy Bounds 
Checking increases the average execution time for SPECINT 2000 benchmarks by 60\%. 
It increases average memory usage by 20\%.

Paricheck \cite{Younan2010} stores a 2-byte label for each 32-byte chunk of memory.
It reserves 1/16 of the virtual address space for a table and increases
the memory object allocation size to 32 bytes.
It checks that pointer arithmetic stays in bounds by checking that the
original pointer and the pointer computed by pointer arithmetic have the
same label. For SPEC CPU2000, it increases average execution time 49\% and
average  memory usage by 9.5\%.

Low Fat Pointers \cite{Duck2016} encode bounds information into 64-bit pointers by
dividing memory into \var{m} regions of 4 GBytes each and storing
the region information in the upper 32-bits of the pointer.  Each
region contains objects of some size $k$ that are aligned to $k$.
A table maps regions to their sizes.  They measure the performance of 
SPEC 2006 programs and find that checking all pointer reads and writes
increases average program execution time by 56\% and checking only writes 
increases average execution time by 13\%.

Finally, we describe shadow memory approaches.
Patil and Fischer \cite{Patil1997}
implement bounds checking using a second process that follows the execution 
of the original process.  They separate the bounds and lifetime information
from the original pointer and use shadow heaps and shadow stacks in the
second process to track it.  
SoftBound \cite{Nagarakatte2009} tracks bounds information
for each  memory location that contains a pointer by using a side table.  
As an example, given a pointer variable,
the system tracks the bounds based on the address of the pointer variable.
This allows the system to track sub-bounds within objects.  The calling
convention for values passed in registers is modified to have an additional
parameters for bounds.  SoftBound uses either a hash table or
a shadow copy of memory to track the bounds information.   The shadow
copy of memory generally has better performance.  With the shadow
copy of memory, SoftBound increases average program execution time for
a set of benchmarks by 67\%.   SoftBound can check only writes, in which
case average program execution time increases by 22\%.   SoftBound increases 
average memory footprint by 64\%, although it can increase it by up to 200\%.

\section{Type-safe dialects of C}

CCured \cite{Necula2005} uses whole-program static analysis to identify 
different uses of pointers in C programs. It identifies pointers that are used to
read or write values only (safe pointers), pointers that are used in pointer
arithmetic also (sequence pointers), and pointers that are involved in
possibly non-type safe casts (wild pointers). It uses a multi-machine
word representation for sequence pointers and wild pointers. It also
changes the representation of data pointed to by wild pointers. This
changes data layouts and causes interoperation problems. The CCured
results clear show that many pointers are never used with pointer
arithmetic. It suggests that new types of pointers should be introduced
into C for pointers that have different safety requirements. This would
be an easy and low-risk way to improve the safety of C programs.

Deputy \cite{Condit2007,Feng2006} uses dependent types to avoid runtime layout changes
in pointers involved in pointer arithmetic. The dependent types allow the bounds of
the pointers to be specified as part of the types of the pointers and
the bounds to depend on runtime values. Deputy requires programmers to
annotate function parameters, data structures, and global parameters
with dependent types. It then infers dependent type annotations for
local variables and adds runtime checks to make the dependently-typed
program type check. The runtime checks enforce that pointer values stay
in bounds. The checks apply to pointer arithmetic and pointer
dereferencing.

Havoc \cite{Condit2009} goes beyond Deputy and allows types to be combined with program
verification. It allows a programmer to specify program invariants that
imply type safety and can verify these invariants statically. It can
handle unsafe code such as using a pointer to a field to access a prior
field in a data structure.

There are some high-level conclusions that we can draw from these
systems. First, it is not feasible in practice to require widespread
data layout changes, as CCured did. Second, this means that use of
program invariants and/or runtime system support will be required to
establish that pointer uses are in bounds. Third, it can be arbitrarily
hard to show the type safety statically of low-level systems
code. The code may be type-safe at runtime. A programmer may intuitively know
that it is type-safe and be able to argue informally for correctness.
However, writing down the invariants may be hard and may require deep
knowledge of program verification techniques. It may also lead to
invariants that are longer and more complicated than the original code.
It may be better for a programmer to just rewrite the code to be type
safe.

Extensions for checked pointer operations will require a trade-off between
dynamic techniques for checking pointer bounds (which are easy to reason
about and understand, but require data layout changes) and static
techniques (which may not be easy to reason about and understand, but do
not require data layout changes).

We can draw the following chart of principles versus techniques:

\begin{longtable}[c]{@{}lll@{}}
\toprule
& Dynamic techniques & Static techniques\tabularnewline
\midrule
\endhead
Minimal & \texttt{Yes} & \texttt{No}\tabularnewline
Succinct and clear & \texttt{Yes} & \texttt{Sometimes}\tabularnewline
Incremental & \texttt{No} & \texttt{Yes}\tabularnewline
\bottomrule
\end{longtable}

One concern about the work is that the more applied work, such as
CCured, Deputy, and SAL, has not been adopted by programmers
enthusiastically. SAL is widely used within Microsoft because it is a
mandated part of the software development process, not because
programmers are enthusiastic about it. It has not been adopted widely
outside of Microsoft. It is unclear why these approaches have not been
adopted. There are many plausible possible reasons, including inertia,
lack of a product-quality toolchain, lack of perceived benefit relative
to the effort, and perhaps being difficult to use. It is important to
aim for something that programmers like. When we are facing design
choices, we recommend using user studies of programmers to evaluate the
choices, instead of relying on hunches or opinions.

\subsection{Using dependent types to enforce checking of pointer bounds}

Deputy adds dependent types to C to specify and track pointer bounds. A
dependent type is a type that may depend on a value at runtime.
Dependent types are built using type constructors that are applied to
types and values. The type constructors capture specific properties of
runtime values. For example, Deputy introduces a type constructor
\verb|Array| that can be applied to an integer value (the length of the
array) and an element type. \verb|Array 5 int| describes the type of
integer arrays with 5 elements. The \verb|Array| type constructor can be
applied to a program variable or an expression, so the type can depend
on a runtime value. For example, \verb|Array n int| describes the type
of integer arrays with n elements.

The following example illustrates the use of dependent types in Deputy.
It is adapted from Figure 3 of the Deputy OSDI paper , which in turn was
adapted from the Deputy version of the Linux e1000 network card driver.

The example has an annotation on the \texttt{buffer\_info} field of
\texttt{e1000\_tx\_ring}. The annotation means that
\texttt{buffer\_info} points at an array element and that at least
\texttt{info\_count} elements are valid (specifically, it is valid to
access memory between \texttt{buffer\_info} and \texttt{buffer\_info +
info\_count - 1}). This information is part of the type of
\texttt{buffer\_info}.

The type checking rule for adding a pointer of \verb|Array| type with an
integer requires that the integer value be in bounds for the array. To
type check \texttt{tx\_ring-\textgreater{}buffer\_info[i]}, the type
checker must show at compile time that \texttt{i >= 0} and
\texttt{i <= tx\_ring->count}. In general, taking
an arbitrary program and establishing equality between runtime values at
compile time is undecidable, which means that type checking would be
undecidable. To make type checking decidable, Deputy examines statements
whose type checking rules require establishing facts at compile-time
that involve runtime values. Deputy systematically inserts run time
checks that establish the relationships are true before the statements.
If a relationship between runtime values is not true, the checks cause
the program to fail at run time. Of course, these runtime checks can be
eliminated by later optimization. In this specific case, the compiler
injects a runtime check \verb|assert(0 <= i && i < tx_ring->info_count);| into the program. 
In the example, the runtime checks are italicized assert statements.

\begin{alltt}
struct e1000_tx_ring \{
    ...
    unsigned int info_count;
    struct e1000_buffer * count(info_count)
        buffer_info;
    ...
\};

static boolean t
e1000_clean_tx_irq(
    struct e1000_adapter *adapter,
    struct e1000_tx_ring *tx_ring)
\{
    ...
    \textit{assert(tx_ring != NULL);}
    spin lock(&tx_ring->tx_lock);
    ...
    i = tx_ring->next_to_clean;
    \textit{assert(0 <= i && i < tx_ring->info_count);}
    eop = tx_ring->buffer_info[i]
    .next to watch;
    ...

    spin unlock(&tx_ring->tx_lock);
\}
\end{alltt}

\subsection{Problems with making {C} function bodies dependently-typed}
\label{section:dependent-typing-issues}

C function bodies need to be rewritten to use dependent types and to be
properly typed according to dependent typing rules. Local pointer
variables must be modified to be dependently-typed. As explained
earlier, this means that runtime checks must be added to the code.
Dependently-typing local pointer variables also requires the addition of
computations to track array bounds and local variables to hold the
results of those computations.

Deputy proposes the use of an inference and rewriting step for C
function bodies automatically during compilation to make C function
bodies dependently-typed. Deputy takes a C program, does inference, and
rewrites the programs so that local variables are properly
dependently-typed. Deputy is able to do this automatically given
programs where method parameters, data structures, and global variables
are annotated with dependent types. Deputy introduces local variables
and computations to track missing dependent information. It also
introduces runtime assertions that check that pointers remain within
range. It is an impressive technical feat that this can be done
automatically.

The rewriting step, however, breaks the principle of preserving the
efficiency and control of C. It introduces computations into the program
that may have significant cost and that are not under programmer
control. For C, it is highly desirable that programmers control the
computations that are added to programs to enforce bounds checking. The
rewriting step also potentially violates the principle of clarity
because understanding program failures may require understanding these
computations.

The following code example from Figure 1 of the Deputy ESOP paper shows
this. Here is the original code:
\begin{verbatim}
int sum (int * buf, int * end) {
    int sum = 0;
    while (buf < end) {
        sum += * buf;
        buf = buf + 1;
    }
    return sum;
}
\end{verbatim}

Here is the Deputy-generated code, assuming that the function parameters
are annotated with dependent types. The new code inserted by Deputy has
been italicized:

\begin{alltt}
int sum (int * count(end - buf) buf, int * end) \{
    int sum = 0;
    while (buf < end) \{
        \textit{assert(0 < end - buf);}
        sum += * buf;
        int tmplen = (end - buf) - 1;
        \textit{assert(0 <= 1 <= end - buf);}
        int * count(tmplen) tmp = buf + 1;
        \textit{assert(0 <= end - tmp <= tmplen);  // how to explain this failure??}
        buf = tmp;
    \}
    return sum;
\}
\end{alltt}

The program now has computations of \texttt{end - buf} and \texttt{end
- tmp} that track the bounds of the array \texttt{buf}. A C programmer
would not expect instructions for these computations to be injected into
the program. This makes the program less efficient and these
instructions are also not introduced under programmer control. In
addition it might be difficult for a programmer to understand a bounds
failure in this program at runtime when the failure involves a
synthesized expression such as \verb|end - tmp <= tmplen| that did not
exist in the original source code.

This suggests that the automatic inference and rewriting during
compilation that Deputy does is not appropriate for C. We will not do
this for Checked C.

\subsection{Problems with dependently-typed {C}}

We have ruled out using an automatic inference and rewriting step during
compilation. If we want to use dependent types to enforce bounds
checking in C, this means that programmers will have to write code
directly in a variant of C that is dependently-typed. It would be
possible to use a Deputy-like to automatically rewrite existing C
programs into this dependently-typed C, provided that dependent-type
annotations have been provided for parameters, global variables, and
data structures. Code could be converted and then programmers could
continue developing their software in a dependently-typed C.

There are several problems with using a dependently-typed variant of C
directly for programming. First, dependent types are a big change to the
C type system and C type checking. Dependent types are a rather abstract
concept that may be hard for many programmers to understand. Even if
programmers can understand dependent types, type checking now becomes a
complicated exercise: to type check a dependently-typed statement, the
type checker must prove that certain runtime invariants are true before
the statement. To illustrate this, consider the type checking rule for
variable assignment from \cite{Condit2007}. This
rule requires that the type checker prove that certain invariants must
be true at runtime before the statement. Type checking becomes entangled
in general reasoning about program invariants.

Second, dependent types do not interact nicely with imperative
programming. The program always has to be well-typed according to
dependent-typing rules. To address this, Deputy introduced a programming
operator that may seem odd to a C programmer: a new parallel assignment
operator.

Consider a structure with a pointer field whose size depends on another
field:
\begin{verbatim}
struct S {
   int * count(len) arr;
   int len;
}
\end{verbatim}

If there is a local variable of type S, neither field of the variable
can be updated independently of the other field:

\begin{verbatim}
S y;
int * count(5) tmp = malloc(sizeof(int) 5);
y.arr = tmp;
y.len = 5;
\end{verbatim}

The assignment to y.arr will fail to type check because y.len is
out-of-date. Reversing the order of assignments does not help. The
solution in Deputy was to introduce a parallel assignment operator. This
is just a specific instance of the problem of initializing a data
structure that satisfies an invariant. In an imperative language,
programmers expect to be able to initialize a data structure using
several assignments and only assert an invariant at the end of
initialization.

Finally, using dependent types makes programs too verbose: explicit
checks to enforce safety have to be inserted all over the code. To our
knowledge, there are no widely-used languages with array-bounds checking
that requires this level of verbosity. In Java and C\#, the checks are
implicitly done. This was the case in older languages such as FORTRAN
and Pascal, as well.

The conclusion is that dependently-typed C at the source level is
not a practical approach. Given that dependent typing is just one way of 
enforcing program invariants,
it suggests that we should explore other ways to enforce program
invariants necessary for bounds safety for C.

\subsection{Tracking pointer bounds dynamically}

A requirement that local variable array bounds be tracked by program
invariants could lead to many invariants. The Deputy authors observe
that the Deputy inference algorithm for local variables produces a
result similar to fat pointers: ``Deputy introduces a fat representation
for locals, whereas for data structures, function parameters, and global
parameters, the programmer must specify how to compute the metadata from
data already existing in the program.'' The bounds for a pointer are
tracked explicitly using other local variables. This suggests that fat
pointers could be used as an alternative to program invariants for local
variables, in cases where using program invariants makes code too
verbose and there is not a constraint on data layout.

Suppose there is a \spanptr\ type constructor where
\spanptr\ is a struct that has a pointer field and lower and
upper bounds on the valid range of memory associated with a pointer.
\spanptr\ values can be used where pointer values can be
used, with safety checks added for various operations. Consider the
original example in Section~\ref{section:dependent-typing-issues}. 
Here is the code for the method using
\spanptr.

\begin{verbatim}
int sum (int * count(end - tmpbuf) tmpbuf, int * end) {
    span<int> buf = new span(tmpbuf, tmpbuf, end);
    int sum = 0;
    while (buf < end) {
        sum += *buf;   // checks that buf is in  bounds before dereferencing it        
        buf = buf + 1; // new struct with updated pointer, same bounds
    }
    return sum;
}
\end{verbatim}

\subsection{Summary of lessons}

It is clear from the CCured results that many C pointers are never used
with pointer arithmetic. This suggests strongly that new types of
pointers should be introduced into C for pointers that have different
safety requirements. This would be an easy and low-risk improvement to
the safety of C programs.

For pointers where pointer arithmetic is allowed, a combination of
dynamic and static techniques will be needed to ensure bounds-safe pointer
operations. Dynamic techniques that change pointer representations allow
succinct and clear code, at the expense of changing data layout and
causing problems with interoperation and likely efficiency. Static
annotations allow programmers to express bounds information for existing
data structures and parameters and support interoperation. The use of
static annotations for local variables is not required: automatic
inference and insertion of computations to maintain bounds information
and check bounds can be done instead. However, the inference and
automatic insertion of computation compromises the control, efficiency,
and clarity desired by C programmers. This suggests that this approach
should not be used. A more suitable approach for C seems to be to embed
the bounds information for local variables directly into programs.

Static annotations that introduce the complex notion of dependent types
into C programs are problematic. We should explore other formulations of
programs invariants may fit better with C.

\section{Security mitigations}
One motivation for adding bounds-checking to C and related languages
such as C++ is security.  Programs that
corrupt memory through out-of-bounds writes or that access memory through
out-of-bounds reads can be exploited in several ways:
\begin{enumerate}
\item  Execution of arbitrary code: An attacker may be able to inject arbitrary machine code into a process and have the process  execute that code.
\item Control-flow attacks: this a more subtle attack that avoids the need to inject arbitrary machine.  An attacker manipulates program state to
stitch together execution of a program of the attacker's choosing
using existing machine code.
For example, in return-oriented programming, an attacker finds segments of useful
machine code that end in return instructions. The attacker manipulates the state of 
the program call  stack to execute a series of small pieces of machine code and execute
a arbitrary program.  There are other ways to manpulate program state to
change control-flow, such as changing the target of an indirect function call.  
This can be done by 
ovewriting a function pointer or the virtual table of an object.
\item Data modification: an attacker may be able to write data to a process, causing the process to take an incorrect action on behalf of an attacker.
\item  Data disclosure: an attacker may be able to read data from a process 
and obtain data, including data that is meant to be confidential.  
\end{enumerate}

A number of security mitigations have been developed and deployed
in practice to address the computer security problems caused by incorrect
C and C++ programs. 
The mitigations include Address-Space Layout Randomization (ASLR), Data Execution
Prevention (DEP), stack canaries,
shadow stacks, and Control-Flow Integrity (CFI).   ASLR, DEP, and CFI focus
on preventing execution of arbitrary code and control-flow modification.  
Stack protection mechanisms focus on protecting data or return addresses
on the stack. ASLR, DEP, CFI, and stack canaries can be 
can be defeated by determined attackers using data modification and data disclosure
attacks.  Shadow stacks do not protect stack-allocated buffers or arrays, 
heap data, and statically-allocated data.

Checked C complements existing security mitigations by providing
protection against data modification and data disclosure attacks.
Chen {\it et al.} \cite{Chen2005} show that data modification
attacks that do not alter control-flow pose a serious long-term threat.
The Heartbleed attack on OpenSSL illustrates the damage this is
possible from even data disclosure attacks.

If a C program and libraries that it uses have been converted to use 
only checked pointers and checked arrays and the program is free of type 
cast or memory management errors, Checked C provides a strong
guarantee about memory reads and writes. Any pointer must have been constructed
via a  series of operations from a pointer to an object.   Checked C ensures 
that the constructed ponter only accesses memory within that object.  

Because Checked C addresses only bounds safety, Checked C programs 
remain vulnerable  to incorrect type casts, memory management errors, 
and race conditions that invalidate bounds information. They are also
vulnerable to data modification by unchecked code in the same address space.

In the remainder of this section, we review security mitigations that
have been deployed in practice. We discuss what they protect against
and how the mitigations can be defeated by data modification and data 
disclosure attacks.

Hardware and OS-based approaches can prevent some attacks that inject and
execute machine code.  At the hardware level, virtual memory support may provide
a ``no execute'' bit for each virtual memory page that forbids the execution
of instructions located on that page of virtual memory.  This bit can be set by
default for program stacks and for memory when it is first allocated. A process
may have to request specifically that an area of virtual memory be made
executable.  This approach does not defend against other attacks, such as
control-flow attacks,  data modification, or data disclosure.  
Control-flow attacks can be used to execute a system call and disable
no execution protection.    

Hardware and OS support for ``no execute'' is widely deployed in production.
For example, hardware support was incorporated into 32 and 64-bit processors
for the Intel x86 architecture in 2005 and 2003, respectively.  Windows
and Linux have supported it from that time as well.  For 32-bit programs on
Windows, programs must opt-in.  That is the default for programs compiled
with the Microsoft Visual C++ compiler, however.

Software can emulate ``no execute'' support or provide approximiations of it
when hardware support is not available. Software fault isolation
\cite{Castro2009, Erlingsson2006,McCamant2006,Wahbe1993} injects checks
into machine code, either during compilation or by rewriting binaries.
It implements address spaces in software for fault isolation. Software components communicate via remote-procedure calls. By implementing address
spaces in software, this avoids expensive hardware context switches.
Wahbe {\it et al} \cite{Wahbe1993} describe how execution of data can be
prevented by placing code and data in separate areas of memory and checking the
targets of  indirect jumps.  Software fault isolation, like hardware-based
approaches, is vulnerable to control-flow attacks, data modification, 
and data disclosure attacks.

ASLR \cite{PaX2003,WikipediaASLR} provides some protection against 
control-flow attacks.   All major production operating systems provide
some form of ASLR. In ASLR, code
sections from executable files are loaded in random locations in the
address space of a process.  In addition, data sections, stacks, and
dynamically-allocated data are also placed in random locations in the address
space of a process. This makes it harder for an attacker to identify the locations of fragments of code to be used in return-oriented programming.  However, ASLR does
not protect against data modification or data disclosure attacks. For example, data 
may be located on the stack adjacent to a
variable that is subject to a buffer overrun; the buffer overrrun can be
be used reliability to overwrite or read the data.   

ASLR can be compromised by data disclosure attacks.  An attacker can obtain the
location of a code section by reading data from the stack, for example, and obtaining function return addresses.  The attacker can then craft an attack based on that data. 
A number of proposals suggested finer-grained  randomization of code layout
\cite{Bhatkar2005, Hiser2012, Kil2006, Pappas2012,Wartell2012}.
For example, code layout can be randomized at the instruction level or
basic-block level. These too are vulnerable to 
data disclosure attacks \cite{Snow2013}.

The idea behind ASLR is to use randomization to protect
code and data addresses.  For randomization of addresses to be effective, 
it requires hardware  architectures that have 64-bit addresses and 
virtual memory support \cite{Shacham2004}.  With 32-bit addresses, 
there is typically  at most 16 bits of entropy available for
virtual memory allocation.  Data is allocated at virtual memory
page granularities or multiples of virtual memory page granularities
and using upper bits fragments the virtual address space, which
could cause large virtual memory allocations to fail.  This
amount of entropy is not enough to defend systems deployed at scale on
the Internet.  An attacker only needs on average 32,768 probes for one system or 
conversely 32,768 target systems to compromise one of them through a
brute force attack.
This limits the usefulness of ASLR in embedded domains where 
64-bit address spaces are uncommon.  

Another set of ideas is to protect the data that contains 
code addresses.  Some ideas aim to protect against modification;
others aim to protect against disclosure of the code addresses.
Stack canaries \cite{Cowan1998, Dang2015, Petsios2015} provide 
some protection against injection of 
arbitrary code and control-flow attacks.
They protect against attacks that modify return addresses
on call stacks by overrunning the bounds of a stack-allocated array.  
This kind of overrun can happen when using C string functions that do
not valid parameter lengths, for example.   A
compiler injects code at function entry points and return
points. Entry point code places a token on the call stack
next to the return address.  Return point code checks that
the token has not been modified before executing the return
instruction.  The value of the token may be computed at run time
and selected to have specific properties that aid in the detection
of overflow attacks.  This form of stack protection is available as a
compiler option for the GCC and Microsoft Visual C++ compilers.

Canaries do not provide protection against data modification attacks
that modify only the contents of stack-allocated variables, that
precisely modify return addresses, or that modify other areas 
of memory such as the heap and global variables. They also do not
provide protection against data disclosure attacks. 

An alternative to stack canaries is shadow stacks \cite{Abadi2005, 
Baratloo2000, Bhatkar2005, Chiueh2001, Corliss2005, Erlingsson2006,
Frantzen2001, Kuznetsov2014}.
With shadow stacks,
the stack is split into two stacks.  One stack is the secure stack. It
is accessible via a dedicated hardware register and placed at a random
location in memory.   The location of the secure stack is protected
against disclosure by guaranteeing that all memory accesses
to the secure stack are in bounds.  For example, only scalar variables whose
addresses are not taken may be stored on the secure stack. In addition, 
the addresses of locations on the secure stack are only stored on the secure
stack.   The other stack is the insecure stack.  Its location is not
protected against disclosure.

In some approaches, the secure stack is used to only hold return addresses.
A return address is stored on the regular stack as well and there is a
check that the return address is unmodified before doing a return.
This incurs an overhead of about 10\% because of the cost of having two
stacks and checking return addresses \cite{Dang2015}.   The
the regular stack can be used as the secure stack and that variables
that may have out-of-bounds memory accesses or whose addresses are taken
can be stored on the insecure stack \cite{Bhatkar2005, Kuznetsov2014}.  
Kuznetsov {\it et al.}.   
\cite{Kuznetsov2014} observe that this improves performance because
many small stack frames do not even need shadow stack frames.  For
SPEC CPU 2006 benchmarks, they found that the performance cost 
ranges from -4.2\% to 4.1\%,
with an average cost of less than 0.1\%.  They speculate
that performance improvements are due to improved data locality for
stack accesses from the placement of large arrays on the insecure stack.
This form of stack protection is available as a compiler option 
for the LLVM compiler.

Shadow stacks do not prevent data modification and data disclosure attacks
against the insecure stack or other areas of memory such as the heap 
and global variables.  Shadow stacks also have backwards compatibility
problems; all code used by a thread must be converted to prevent disclosure
of the shadow stack location for the thread.  

A shadow stack that uses the regular stack can be attacked in
a subtle way, even if all memory accesses to the stack
are guaranteed to be in bounds.  An attacker can cause a calling convention
mismatch, where the caller of a function and the called function disagree on
the size of argument data that is passed on the stack or who is expected to
make adjustments to the stack pointer.  This corrupts the stack pointer, 
allowing a data modification or data disclosure attack against the shadow stack, including overwriting return addresses \cite{Goktas2014}.

Like ASLR, shadow stacks that use the regular call stack may be vulnerable to 
brute-force data disclosure attacks on systems with 32-bit addresses.
For example, on a 32-bit Windows system, the smallest possible
stack size is 64K and the uppermost 1 GByte of virtual address space
is not available by default.  If an attacker is able to read a byte 
in memory at an attacker-selected location and the attack randomly picks
the location,  an attacker has a 1 in 49,152 
chance of reading a byte that is on a virtual memory page that contains a 
shadow stack location.  With reads of nearby locations, an attacker can likely 
determine if the page containing the byte contains part of a stack.

Control-flow integrity (CFI) also provides some protection
against return-oriented programming attacks \cite{Abadi2005}.  There
have been many follow-up papers \cite{Akritidis2008, Li2011, Li2010, Mashtizadeh2015,
NiuPLDI2014, NiuCCS2014, Niu2015, Sadeghi2015, Tice2014, 
vanderVeen2015, Wang2015, Wang2010, Zeng2011, ZhangSP2013,Zhang2015, ZhangSEC2013}.
CFI adds runtime checks to machine code to ensure
that a program follows an approximation of the valid control-flow of the program. 
In the description in \cite{Abadi2005}, a compiler computes the target addresses of each 
indirect  function call and each return instruction.  The
compiler groups addresses into equivalence classes: addresses are in the same 
class if they may be the target of the same call or return instruction.  This is
used to generate unique identifiers for the runtime control-flow check. 
Many different variants of CFI have been proposed, including coarse-grained CFI
implementations that are less precise than the original description \cite{Wang2015,
ZhangSP2013, ZhangSEC2013} 
as well as fine-grained CFI implementations \cite{Tice2014,Wang2010} 
and even context-sensitive CFI implementations \cite{vanderVeen2015}.
CFI has been applied in production C and C++ compilers to indirect function
calls and not applied to return instructions
\cite{GCCCFG2016,LLVMCFG2016,MicrosoftCFG2016, Tice2014}.   Return instructions
are protected via other means such as stack canaries or shadow stacks.  
CFI is implemented in various forms in production versions of the
GCC, LLVM, and Microsoft Visual C++ compilers.

CFI does not defend against data modification or data disclosure attacks. 
It is also vulnerable to data modification attacks.  Determined attackers can
use a data modification attack to still construct a control-flow attack
\cite{Carlini2015, Conti2015, Evans2015, Goktas2014}.
The runtime control-flow checks are imprecise because the control-flow graph (CFG)
is an approximation of the actual control-flow that is possible for
a program.  The computed CFG must allow at least all legal executions of a
program. In fact it allows invalid executions of a program too.  The
attacker can take advantage of that difference to control execution of the program
via a data modification attack.

CFI is based on the assumption that a precise control-flow graph can be
constructed for C and C++ programs.  According to Evans {\it et al.} \cite{Evans2015},
``this assumption is tenuous at best''.  It is difficult to construct
a precise CFG for programs with pointers that use function pointers and
object-oriented language features.  Coarse-grained CFI implementations make the
checked CFG even less precise.  They do this to reduce  the cost of runtime checking or 
because of difficulties computing a precise CFG.  For example, binary rewriting
approaches have difficulty precisely computing possible targets for indirect jumps.
This allows even more invalid executions.  Coarse-grained CFI implementations
were  first shown to be vulnerable to an 
attack based on the imprecision of the checks \cite{Carlini2014,Davi2014,Goktas2014}. 
Fine-grained CFI implementations are also vulnerable to the same kind of attack
\cite{Carlini2015,Evans2015}.

Evans {\it et al} \cite{Evans2015} explain how constructing the CFG relies on a
points-to analysis for pointers.  Sound and complete points-to analysis is 
undecidable \cite{Ramalingam1994}, so points-to analyses implemented in compilers 
must approximate the the actual points-to behavior of programs.  This leads to 
imprecise CFGs in practice.

It is also difficult to construct a precise CFG in the presence of 
separately-compiled dynamically-loaded libraries \cite{NiuPLDI2014} or just-in-time
compiled code \cite{NiuCCS2014}.  Tice {\it et al.} \cite{Tice2014} discuss the difficulties of implementing CFI for programs that use dynamically-loaded libraries. 
Hand-written assembly code also causes problems for constructing a precise CFG.
